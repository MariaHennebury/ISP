#Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score, mean_absolute_error

from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer

# File path
morbidity_file_path = 'database_var.csv'

# Read the CSV file into a DataFrame with 'latin-1' encoding
morbidity_df = pd.read_csv(morbidity_file_path, encoding='latin-1')


# Mapping of variable numbers to variable names
variable_mapping_morbidity = {
    'v1': 'Geography',
    'v2': 'Geography Type',
    'v3': 'Geography Note',
    'v4': 'Year Grouping',
    'v5': 'Gender',
    'v6': 'Hospital morbidity',
    'v7': 'Diseases of the circulatory system',
    'v8': 'Heart disease',
    'v9': 'Diseases of the digestive system',
    'v10': 'Diseases of intestine and peritoneum',
    'v11': 'Diseases of gallbladder',
    'v12': 'Diseases of esophagus, stomach and duodenum',
    'v13': 'Ulcer',
    'v14': 'Diseases of the respiratory system',
    'v15': 'Chronic obstructions, pulmonary diseases, etc',
    'v16': 'Pneumonia',
    'v17': 'Asthma',
    'v18': 'Diseases of the upper respiratory tract',
    'v19': 'Chronic diseases of tonsils and adenoids',
    'v20': 'Acute upper respiratory infections',
    'v21': 'Diseases of the genitourinary system',
    'v22': 'Diseases of female genital organs',
    'v23': 'Diseases of the urinary system',
    'v24': 'Diseases of male genital organs',
    'v25': 'Injury and poisoning',
    'v26': 'Fractures',
    'v27': 'Neoplasms (cancer)',
    'v28': 'Malignant neoplasms',
    'v29': 'Age Group: Less than 20',
    'v30': 'Age Group: 0-4',
    'v31': 'Age Group: 5-9',
    'v32': 'Age Group: 10-14',
    'v33': 'Age Group: 15-19',
    'v34': 'Age Group: 20 to 34',
    'v35': 'Age Group: 20-24',
    'v36': 'Age Group: 25-29',
    'v37': 'Age Group: 30-34',
    'v38': 'Age Group: 35 to 54',
    'v39': 'Age Group: 35-39',
    'v40': 'Age Group: 40-44',
    'v41': 'Age Group: 45-49',
    'v42': 'Age Group: 50-54',
    'v43': 'Age Group: 55+',
    'v44': 'Age Group: 55-59',
    'v45': 'Age Group: 60-64',
    'v46': 'Age Group: 65+',
    'v47': 'Age Group: 65-74',
    'v48': 'Age Group: 75-84',
    'v49': 'Age Group: 85+',
    'v50': 'Age Group: 60+',
    'v51': 'Other diagnoses',
    'v52': 'Other diagnoses: Age less than 20',
    'v53': 'Other diagnoses: Age 20-39',
    'v54': 'Other diagnoses: Age 40-59',
    'v55': 'Other diagnoses: Age 60+',
    'v56': 'Median age',
    'v57': 'Days in hospital (average)'
}

# Rename columns using the mapping
morbidity_df.rename(columns=variable_mapping_morbidity, inplace=True)


# Display duplicate columns if any
duplicates = morbidity_df.columns[morbidity_df.columns.duplicated()].tolist()
print(f"Duplicate columns found: {duplicates}")

# Remove duplicate columns
morbidity_df = morbidity_df.loc[:, ~morbidity_df.columns.duplicated()]


# Features to include in testing
features = [
    'Diseases of the circulatory system',
    'Heart disease',
    'Diseases of the upper respiratory tract',
    'Diseases of the respiratory system',
    'Diseases of gallbladder',
    'Diseases of the genitourinary system',
    'Diseases of the urinary system',
    'Diseases of intestine and peritoneum',
    'Diseases of esophagus, stomach and duodenum',
    'Diseases of female genital organs',
    'Other diagnoses',
    'Asthma',
    'Chronic obstructions, pulmonary diseases, etc',
    'Chronic diseases of tonsils and adenoids',
    'Acute upper respiratory infections',
    'Diseases of male genital organs',
    'Neoplasms (cancer)',
    'Malignant neoplasms',
    'Pneumonia',
    'Fractures',
    'Age Group: 0-4',
    'Age Group: 5-9',
    'Age Group: 10-14',
    'Age Group: 15-19',
    'Age Group: 20 to 34',
    'Age Group: 35 to 54',
    'Age Group: 55-59',
    'Age Group: 60-64',
    'Age Group: 65-74',
    'Age Group: 75-84',
    'Age Group: 85+',
    'Ulcer',
    'Other diagnoses: Age less than 20',
    'Other diagnoses: Age 20-39',
    'Other diagnoses: Age 40-59',
    'Other diagnoses: Age 60+'
]

target_col = 'Days in hospital (average)'

# Work with a copy of the DataFrame
morbidity_df = morbidity_df.copy()

# Convert target column to numeric, coercing errors to NaN
morbidity_df[target_col] = pd.to_numeric(morbidity_df[target_col], errors='coerce')

# Drop rows where target is NaN
morbidity_df = morbidity_df.dropna(subset=[target_col])

# Ensure that the feature columns are numeric or handle non-numeric values
X = morbidity_df[features].copy()
y = morbidity_df[target_col].copy()

# Convert feature columns to numeric where applicable
for col in X.columns:
    if X[col].dtype == 'object':
        X[col] = pd.to_numeric(X[col], errors='coerce')

# Drop rows with NaN values in features
X = X.dropna()

# Ensure that y is aligned with X after dropping NaNs
y = y.loc[X.index]

# Define numerical and categorical features
numeric_features = X.select_dtypes(include=['int64', 'float64']).columns
categorical_features = X.select_dtypes(include=['object']).columns

# Define preprocessing pipelines
numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='mean')),  # Impute missing values with mean
    ('scaler', StandardScaler())  # Scale numerical features
])

categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values with most frequent value
    ('onehot', OneHotEncoder(handle_unknown='ignore', drop='first'))  # One-hot encode categorical features
])

# Combine preprocessing pipelines
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)
    ])

# Create a pipeline that includes preprocessing and model
pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('regressor', RandomForestRegressor(random_state=42))
])

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Fit the pipeline on the training data
pipeline.fit(X_train, y_train)

# Predict on the test set
y_pred = pipeline.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)

print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")
print(f"Mean Absolute Error: {mae}")


# Define the parameter grid for Grid Search
param_grid = {
    'preprocessor__num__scaler__with_mean': [True, False],
    'regressor__n_estimators': [100, 200, 300],
    'regressor__max_depth': [None, 10, 20, 30],
    'regressor__min_samples_split': [2, 5, 10],
    'regressor__min_samples_leaf': [1, 2, 4]
}

# Create a pipeline with preprocessing and RandomForestRegressor
pipeline = Pipeline(steps=[
    ('preprocessor', ColumnTransformer(
        transformers=[
            ('num', Pipeline(steps=[
                ('imputer', SimpleImputer(strategy='mean')),
                ('scaler', StandardScaler())
            ]), numeric_features),
            ('cat', Pipeline(steps=[
                ('imputer', SimpleImputer(strategy='most_frequent')),
                ('onehot', OneHotEncoder(handle_unknown='ignore', drop='first'))
            ]), categorical_features)
        ]
    )),
    ('regressor', RandomForestRegressor(random_state=42))
])

# Set up Grid Search
grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)

# Fit Grid Search
grid_search.fit(X, y)

# Best parameters and best score
print("Best Parameters:", grid_search.best_params_)
print("Best Score (Negative Mean Squared Error):", grid_search.best_score_)
